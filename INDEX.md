# Jugend musiziert Web Scraper - Complete Project

## ğŸµ Project Overview

A comprehensive Python web scraping solution for extracting participant data from the Jugend musiziert regional tournament website. This project includes two scraping approaches, data processing tools, extensive documentation, and working examples.

**Website Target**: https://www.jugend-musiziert.org/wettbewerbe/regionalwettbewerbe/baden-wuerttemberg/esslingen-goeppingen-und-rems-murr/zeitplan

## ğŸ“ Project Files

### Core Scrapers
| File | Purpose | Speed | Complexity |
|------|---------|-------|-----------|
| `scraper.py` | HTTP-based scraper with API discovery | âš¡ 1-5s | Basic |
| `scraper_selenium.py` | JavaScript-enabled scraper | ğŸ¢ 10-30s | Advanced |

### Utilities
| File | Purpose | Usage |
|------|---------|-------|
| `data_processor.py` | Data analysis and export | `python data_processor.py <file.json>` |
| `examples.py` | Interactive usage examples | `python examples.py` |

### Configuration
| File | Purpose |
|------|---------|
| `config.json` | Configuration settings |
| `requirements.txt` | Python dependencies |
| `.gitignore` | Git ignore rules |

### Documentation
| File | Target Audience | Content |
|------|-----------------|---------|
| **README.md** | All users | Complete feature documentation |
| **QUICKSTART.md** | Beginners | 5-minute setup guide |
| **PROJECT_SUMMARY.md** | Technical readers | Architecture and design |
| **API_REFERENCE.md** | Developers | Technical specifications |

## ğŸš€ Quick Start

### 1. Install
```bash
pip install -r requirements.txt
```

### 2. Run
```bash
python scraper.py
```

### 3. Analyze
```bash
python data_processor.py jugend_musiziert_data.json --summary
```

**Output**: `jugend_musiziert_data.json` containing discovered API endpoints and embedded JSON data.

## ğŸ“‹ Feature Checklist

### Scraping Features
- âœ… Automatic API endpoint discovery
- âœ… JSON extraction from script tags
- âœ… NextJS/React data handling
- âœ… JavaScript rendering (Selenium)
- âœ… Window object inspection
- âœ… Error recovery

### Data Processing
- âœ… Participant extraction
- âœ… Category filtering
- âœ… Age group filtering
- âœ… Data grouping
- âœ… CSV export
- âœ… Data summarization

### Documentation
- âœ… README with all features
- âœ… Quick start guide
- âœ… Usage examples (5 scenarios)
- âœ… API reference
- âœ… Project architecture
- âœ… Troubleshooting guide
- âœ… Configuration reference

### Code Quality
- âœ… Type hints
- âœ… Comprehensive logging
- âœ… Error handling
- âœ… Code comments
- âœ… Modular design
- âœ… Configuration file
- âœ… .gitignore

## ğŸ“š Documentation Map

```
START HERE:
â”œâ”€ First time? â†’ QUICKSTART.md (5 min read)
â”œâ”€ Want full docs? â†’ README.md (20 min read)
â”œâ”€ Need examples? â†’ examples.py (interactive)
â”œâ”€ Technical details? â†’ API_REFERENCE.md (reference)
â””â”€ Overview? â†’ PROJECT_SUMMARY.md (this file)
```

## ğŸ”§ What You Can Do

### As a Beginner
1. Install dependencies
2. Run `python scraper.py`
3. View results in JSON file
4. Use `data_processor.py` to analyze

### As a Developer
1. Extend scraper with custom patterns
2. Integrate with database
3. Build scheduling with APScheduler
4. Create visualization dashboard
5. Add export formats (Excel, CSV, etc.)

### As a Data Analyst
1. Extract participant data
2. Filter by category/age
3. Export to CSV/Excel
4. Perform statistical analysis
5. Create reports

## ğŸ¯ Key Capabilities

### Scraper.py
```python
scraper = JugendMusiziertScraper(url)
endpoints = scraper._find_api_endpoints()      # Discover APIs
data = scraper.scrape_schedule()               # Extract JSON
scraper.save_data(data, 'output.json')         # Save results
```

### Data Processor.py
```python
processor = DataProcessor('data.json')
participants = processor.extract_participants()
filtered = processor.filter_by_category(participants, 'Drum-Set')
processor.export_to_csv(filtered, 'output.csv')
```

## ğŸ” What Gets Scraped

The scraper extracts:

**Tournament Information**
- Competition dates and times
- Venues and hall locations
- Categories and age groups

**Participant Data**
- Name and hometown
- Instrument
- Age group
- Ensemble composition

**Program Information**
- Composers and pieces
- Duration
- Movement details

## ğŸ“Š Output Examples

### Raw JSON Output
```json
{
  "url": "https://...",
  "endpoints_discovered": [
    "/api/schedule",
    "/api/participants"
  ],
  "embedded_data": [
    {
      "source": "script_data_VARIABLE",
      "data": { ... }
    }
  ]
}
```

### CSV Export
```csv
name,instrument,location,age_group,category
Patrick Meier,Akkordeon,MÃ¼hlacker,V,Akkordeon-Kammermusik
Nicola Witzmann,Violine,NÃ¼rtingen,V,Akkordeon-Kammermusik
```

## âš™ï¸ Configuration

All settings in `config.json`:
- Target URLs
- Output file paths
- Request timeouts
- Selenium settings
- Regex patterns

## ğŸ Python Requirements

- **Python**: 3.8+
- **Core**: requests >= 2.28.0
- **Optional**: selenium, pandas, openpyxl

## ğŸ“– Documentation Highlights

### README.md
- Complete feature documentation
- Installation instructions (basic + advanced)
- Usage examples
- API patterns explanation
- Customization guide
- Troubleshooting section
- Performance notes

### QUICKSTART.md
- 5-minute setup
- Common tasks
- Quick examples
- Troubleshooting tips

### API_REFERENCE.md
- Architecture diagram
- Class references
- API endpoint patterns
- Data structure examples
- Error handling guide
- Performance optimization
- Testing templates

### PROJECT_SUMMARY.md
- Project components
- File structure
- Usage scenarios
- Technology stack
- Extension ideas

## ğŸ¨ Architecture

```
Website
  â†“
scraper.py â”€â”€â”€â”€â†’ API Discovery
                 JSON Extraction
                 HTML Parsing
  â†“
jugend_musiziert_data.json
  â†“
data_processor.py â”€â”€â”€â”€â†’ Extract
                        Filter
                        Group
                        Export
  â†“
CSV / Analysis / DB
```

## ğŸš€ Getting Started in 3 Steps

### Step 1: Install (< 1 min)
```bash
cd /Users/marcel/projects/jumu
pip install -r requirements.txt
```

### Step 2: Scrape (< 1 min)
```bash
python scraper.py
```

### Step 3: Analyze (< 1 min)
```bash
python data_processor.py jugend_musiziert_data.json --summary
```

**Total time: ~3 minutes to go from zero to data!**

## ğŸ“ Example Use Cases

### Use Case 1: Research
Run scraper â†’ Export to CSV â†’ Analyze tournament participation trends

### Use Case 2: Monitoring
Schedule scraper to run daily â†’ Track participant list changes

### Use Case 3: Integration
Import scraper in your Python app â†’ Embed tournament data

### Use Case 4: Data Science
Export data â†’ Load in Pandas â†’ Create visualizations

### Use Case 5: Website
Run scraper â†’ Store in database â†’ Display on your site

## ğŸ¯ Next Steps

**For Beginners:**
1. Read QUICKSTART.md (5 min)
2. Run the basic scraper
3. Explore the output JSON

**For Developers:**
1. Review API_REFERENCE.md
2. Customize regex patterns in config.json
3. Extend with your own features
4. Check examples.py for integration patterns

**For Data Analysis:**
1. Run scraper
2. Use data_processor.py to extract participants
3. Export to CSV
4. Analyze with your tools

## ğŸ”— Related Files

- Source: `/Users/marcel/projects/jumu/`
- Main scraper: `scraper.py`
- Configuration: `config.json`
- Full docs: `README.md`

## ğŸ“š Learning Resources

- Python Requests: https://docs.python-requests.org/
- Regex Guide: https://regex101.com/
- Selenium: https://selenium-python.readthedocs.io/
- JSON Processing: https://docs.python.org/3/library/json.html

## ğŸ‰ Success Criteria

âœ… Project is complete when you can:
1. Run `python scraper.py` successfully
2. View data in `jugend_musiziert_data.json`
3. Process data with `data_processor.py`
4. Export results to CSV
5. Understand how to customize for other URLs

## ğŸ’¡ Tips & Tricks

- **Fastest approach**: Use `scraper.py` (HTTP-based)
- **Most thorough**: Use `scraper_selenium.py` (JavaScript)
- **Debug mode**: Set `logging.basicConfig(level=logging.DEBUG)`
- **Custom patterns**: Edit regex in `config.json`
- **Schedule scraping**: Use `APScheduler` integration
- **Database storage**: Use SQLite template in examples

## ğŸ”’ Ethical Considerations

- âœ… Respects robots.txt
- âœ… Implements rate limiting ready
- âœ… Comprehensive error handling
- âœ… Responsible data usage
- âœ… Transparent logging

## â“ FAQ

**Q: How often can I run the scraper?**
A: Check the website's terms. Add delays between requests for large batches.

**Q: Does it work with other Jugend musiziert competitions?**
A: Yes! Change the URL in config.json or pass different URL to scraper.

**Q: Can I export to Excel?**
A: CSV is built-in. For Excel, install openpyxl and extend data_processor.py.

**Q: How do I schedule automatic scraping?**
A: Use APScheduler (see examples.py template).

**Q: What if the website changes?**
A: Update regex patterns in config.json or file an issue.

---

## ğŸ“‹ Checklist Before Using

- [ ] Python 3.8+ installed
- [ ] Requirements installed: `pip install -r requirements.txt`
- [ ] URL is accessible
- [ ] Write permissions in directory
- [ ] Read QUICKSTART.md

## ğŸŠ You're All Set!

Your Jugend musiziert scraper is ready to use:

```bash
python scraper.py
```

Check **QUICKSTART.md** for next steps!

---

**Version**: 1.0  
**Created**: January 2026  
**Status**: âœ… Production Ready
